{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkggFqXzvmjv"
      },
      "source": [
        "# Machine Learning\n",
        "## Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTJPkICReSdY"
      },
      "source": [
        "##0. Environment settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tz7d338Aw1dX"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "\n",
        "from keras import layers\n",
        "from keras.layers import Input, Dense, Activation, LSTM, RepeatVector, TimeDistributed\n",
        "from keras.models import Sequential\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from numpy import quantile, where, random\n",
        "\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import RMSprop, SGD\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcYjyTHw1raA",
        "outputId": "17128048-74e3-463c-eeb2-f01dc8fa0f7f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Drive mounting in Google Colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/gdrive\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgCwQgb0vuaE"
      },
      "source": [
        "##1. Data examination"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K904iVTzwpBj",
        "outputId": "49a9c9e1-43e2-4019-95fc-75927dac0036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Dataset length (rows, columns) :\n",
            "(15360, 12)\n",
            "\n",
            "Number of null values :\n",
            "Unnamed: 0    0\n",
            "cfo_demod     0\n",
            "gain_imb      0\n",
            "iq_imb        0\n",
            "or_off        0\n",
            "quadr_err     0\n",
            "m_power       0\n",
            "ph_err        0\n",
            "mag_err       0\n",
            "evm           0\n",
            "Tosc          0\n",
            "Tmix          0\n",
            "dtype: int64\n",
            "\n",
            "Dataset feature names :\n",
            "Index(['Unnamed: 0', 'cfo_demod', 'gain_imb', 'iq_imb', 'or_off', 'quadr_err',\n",
            "       'm_power', 'ph_err', 'mag_err', 'evm', 'Tosc', 'Tmix'],\n",
            "      dtype='object')\n",
            "\n",
            "Data from 5 first rows :\n",
            "   Unnamed: 0   cfo_demod  gain_imb     iq_imb     or_off  quadr_err  \\\n",
            "0           0  592.234802  0.048079 -35.082729 -28.560846   1.993170   \n",
            "1           1 -103.302032 -0.019917 -29.946953 -35.798664  -3.642311   \n",
            "2           2 -582.331299  0.036379 -32.096672 -31.905628   2.835839   \n",
            "3           3 -630.611267  0.063928 -38.216297 -30.084171   1.346316   \n",
            "4           4 -415.526978 -0.055761 -29.180740 -36.601025  -3.963526   \n",
            "\n",
            "    m_power    ph_err   mag_err       evm  Tosc  Tmix  \n",
            "0 -0.499721  1.107926  1.507550  2.423943  39.9  47.6  \n",
            "1 -0.928193  1.236059  2.741568  3.458056  14.8  23.1  \n",
            "2 -1.272485  1.282163  2.140096  3.013522  42.5  48.6  \n",
            "3 -0.596438  1.154848  1.093465  2.254514  26.1  35.4  \n",
            "4  0.113055  1.498889  3.608737  4.286684  24.2  40.8  \n",
            "\n",
            "Data from 5 last rows :\n",
            "       Unnamed: 0   cfo_demod  gain_imb     iq_imb     or_off  quadr_err  \\\n",
            "15355       15355 -476.575653  0.039874 -39.792461 -29.962997   1.143736   \n",
            "15356       15356 -345.645508  0.077925 -32.963398 -27.998444   2.524010   \n",
            "15357       15357 -613.989807  0.090771 -38.951530 -28.111988   1.145893   \n",
            "15358       15358 -997.769531  0.099840 -39.532818 -27.819826   1.014136   \n",
            "15359       15359  450.446838  0.068571 -34.959385 -28.346176   1.996514   \n",
            "\n",
            "        m_power    ph_err   mag_err       evm  Tosc  Tmix  \n",
            "15355 -0.688359  1.175517  1.044636  2.224311  24.6  33.8  \n",
            "15356 -1.135376  1.159356  1.948950  2.761400  55.1  62.7  \n",
            "15357  0.352151  0.995857  0.938308  1.939818  39.5  46.9  \n",
            "15358  0.040398  1.069736  0.875986  2.026062  51.7  58.4  \n",
            "15359 -0.368385  1.035648  1.527475  2.357938  45.4  52.9  \n",
            "\n",
            "Whole dataset :\n",
            "       Unnamed: 0   cfo_demod  gain_imb     iq_imb     or_off  quadr_err  \\\n",
            "0               0  592.234802  0.048079 -35.082729 -28.560846   1.993170   \n",
            "1               1 -103.302032 -0.019917 -29.946953 -35.798664  -3.642311   \n",
            "2               2 -582.331299  0.036379 -32.096672 -31.905628   2.835839   \n",
            "3               3 -630.611267  0.063928 -38.216297 -30.084171   1.346316   \n",
            "4               4 -415.526978 -0.055761 -29.180740 -36.601025  -3.963526   \n",
            "...           ...         ...       ...        ...        ...        ...   \n",
            "15355       15355 -476.575653  0.039874 -39.792461 -29.962997   1.143736   \n",
            "15356       15356 -345.645508  0.077925 -32.963398 -27.998444   2.524010   \n",
            "15357       15357 -613.989807  0.090771 -38.951530 -28.111988   1.145893   \n",
            "15358       15358 -997.769531  0.099840 -39.532818 -27.819826   1.014136   \n",
            "15359       15359  450.446838  0.068571 -34.959385 -28.346176   1.996514   \n",
            "\n",
            "        m_power    ph_err   mag_err       evm  Tosc  Tmix  \n",
            "0     -0.499721  1.107926  1.507550  2.423943  39.9  47.6  \n",
            "1     -0.928193  1.236059  2.741568  3.458056  14.8  23.1  \n",
            "2     -1.272485  1.282163  2.140096  3.013522  42.5  48.6  \n",
            "3     -0.596438  1.154848  1.093465  2.254514  26.1  35.4  \n",
            "4      0.113055  1.498889  3.608737  4.286684  24.2  40.8  \n",
            "...         ...       ...       ...       ...   ...   ...  \n",
            "15355 -0.688359  1.175517  1.044636  2.224311  24.6  33.8  \n",
            "15356 -1.135376  1.159356  1.948950  2.761400  55.1  62.7  \n",
            "15357  0.352151  0.995857  0.938308  1.939818  39.5  46.9  \n",
            "15358  0.040398  1.069736  0.875986  2.026062  51.7  58.4  \n",
            "15359 -0.368385  1.035648  1.527475  2.357938  45.4  52.9  \n",
            "\n",
            "[15360 rows x 12 columns]\n"
          ]
        }
      ],
      "source": [
        "# Define the path to the dataset\n",
        "path_to_dataset = '/content/gdrive/My Drive/ML - Projet/x_train.csv'\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv(path_to_dataset)\n",
        "\n",
        "# Get the dataset length\n",
        "print('\\nDataset length (rows, columns) :')\n",
        "print(dataset.shape)\n",
        "\n",
        "# Check the number of null values for each column\n",
        "print('\\nNumber of null values :')\n",
        "print(dataset.isnull().sum())\n",
        "\n",
        "# Get dataset feature names\n",
        "print('\\nDataset feature names :')\n",
        "print(dataset.columns)\n",
        "\n",
        "# Get data from the 5 first rows\n",
        "print('\\nData from 5 first rows :')\n",
        "print(dataset.head(5))\n",
        "\n",
        "# Get data from the 5 last rows\n",
        "print('\\nData from 5 last rows :')\n",
        "print(dataset.tail(5))\n",
        "\n",
        "# Get the whole data\n",
        "print('\\nWhole dataset :')\n",
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bBrY2-C-v0hK"
      },
      "source": [
        "##2. Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tgvVNxa5wq1s",
        "outputId": "d48ee2cd-07b1-4e99-994a-5f6aa7ce44b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "y_train :\n",
            "        Unnamed: 0  target\n",
            "0               0       5\n",
            "1               1       1\n",
            "2               2       6\n",
            "3               3       3\n",
            "4               4       2\n",
            "...           ...     ...\n",
            "15355       15355       3\n",
            "15356       15356       8\n",
            "15357       15357       7\n",
            "15358       15358       7\n",
            "15359       15359       5\n",
            "\n",
            "[15360 rows x 2 columns]\n",
            "\n",
            "y_train_encoded :\n",
            "        1  2  3  4  5  6  7  8\n",
            "0      0  0  0  0  1  0  0  0\n",
            "1      1  0  0  0  0  0  0  0\n",
            "2      0  0  0  0  0  1  0  0\n",
            "3      0  0  1  0  0  0  0  0\n",
            "4      0  1  0  0  0  0  0  0\n",
            "...   .. .. .. .. .. .. .. ..\n",
            "15355  0  0  1  0  0  0  0  0\n",
            "15356  0  0  0  0  0  0  0  1\n",
            "15357  0  0  0  0  0  0  1  0\n",
            "15358  0  0  0  0  0  0  1  0\n",
            "15359  0  0  0  0  1  0  0  0\n",
            "\n",
            "[15360 rows x 8 columns]\n",
            "\n",
            "x_test features :\n",
            "Index(['cfo_demod', 'gain_imb', 'iq_imb', 'or_off', 'quadr_err', 'ph_err',\n",
            "       'mag_err', 'evm'],\n",
            "      dtype='object')\n",
            "\n",
            "x_train features :\n",
            "Index(['cfo_demod', 'gain_imb', 'iq_imb', 'or_off', 'quadr_err', 'ph_err',\n",
            "       'mag_err', 'evm'],\n",
            "      dtype='object')\n",
            "\n",
            "x_train_encoded :         cfo_demod  gain_imb     iq_imb     or_off  quadr_err    ph_err  \\\n",
            "0      592.234802  0.048079 -35.082729 -28.560846   1.993170  1.107926   \n",
            "1     -103.302032 -0.019917 -29.946953 -35.798664  -3.642311  1.236059   \n",
            "2     -582.331299  0.036379 -32.096672 -31.905628   2.835839  1.282163   \n",
            "3     -630.611267  0.063928 -38.216297 -30.084171   1.346316  1.154848   \n",
            "4     -415.526978 -0.055761 -29.180740 -36.601025  -3.963526  1.498889   \n",
            "...           ...       ...        ...        ...        ...       ...   \n",
            "15355 -476.575653  0.039874 -39.792461 -29.962997   1.143736  1.175517   \n",
            "15356 -345.645508  0.077925 -32.963398 -27.998444   2.524010  1.159356   \n",
            "15357 -613.989807  0.090771 -38.951530 -28.111988   1.145893  0.995857   \n",
            "15358 -997.769531  0.099840 -39.532818 -27.819826   1.014136  1.069736   \n",
            "15359  450.446838  0.068571 -34.959385 -28.346176   1.996514  1.035648   \n",
            "\n",
            "        mag_err       evm  \n",
            "0      1.507550  2.423943  \n",
            "1      2.741568  3.458056  \n",
            "2      2.140096  3.013522  \n",
            "3      1.093465  2.254514  \n",
            "4      3.608737  4.286684  \n",
            "...         ...       ...  \n",
            "15355  1.044636  2.224311  \n",
            "15356  1.948950  2.761400  \n",
            "15357  0.938308  1.939818  \n",
            "15358  0.875986  2.026062  \n",
            "15359  1.527475  2.357938  \n",
            "\n",
            "[15360 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "# Import all the data\n",
        "x_test_original = pd.read_csv('/content/gdrive/My Drive/ML - Projet/x_test.csv')\n",
        "x_train_original = pd.read_csv('/content/gdrive/My Drive/ML - Projet/x_train.csv')\n",
        "y_train_original = pd.read_csv('/content/gdrive/My Drive/ML - Projet/y_train.csv')\n",
        "\n",
        "# Work on copies of the original files\n",
        "x_test = x_test_original.copy()\n",
        "x_train = x_train_original.copy()\n",
        "y_train = y_train_original.copy()\n",
        "\n",
        "# Get only y_train useful data (column 2)\n",
        "print('\\ny_train :\\n', y_train)\n",
        "y_train_column2 = y_train['target']\n",
        "\n",
        "# Classifying y_train values into 8 different classes (from 1 to 8 (max value))\n",
        "#y_train_encoded = to_categorical(y_train_column2, num_classes=None)  # 9 different classes (from 0 to 8 (max value))\n",
        "y_train_encoded = pd.get_dummies(y_train_column2)\n",
        "print('\\ny_train_encoded :\\n', y_train_encoded)\n",
        "\n",
        "# Remove unwanted features (m_power, tosc, tmix)\n",
        "x_test = x_test.drop(['Unnamed: 0','m_power', 'Tosc', 'Tmix'], axis=1)\n",
        "x_train = x_train.drop(['Unnamed: 0','m_power', 'Tosc', 'Tmix'], axis=1)\n",
        "\n",
        "# Check the features removing\n",
        "print('\\nx_test features :')\n",
        "print(x_test.columns)\n",
        "print('\\nx_train features :')\n",
        "print(x_train.columns)\n",
        "\n",
        "# Classifying x_train values into different classes\n",
        "x_train_encoded = pd.get_dummies(x_train)\n",
        "print('\\nx_train_encoded :', x_train_encoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9IfnUYyv29Z"
      },
      "source": [
        "##3.  Model building"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dYg4NXcwsmO",
        "outputId": "b03fb285-85e8-4ea4-e7e6-da8525565928"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 72        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4)                 36        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 8)                 40        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 148\n",
            "Trainable params: 148\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "\n",
        "# Add input layer\n",
        "model.add(Input(shape=(8,)))\n",
        "\n",
        "# Add hidden layers\n",
        "model.add(Dense(8, activation = 'relu'))\n",
        "model.add(Dense(4, activation = 'relu'))\n",
        "\n",
        "# Add output layer\n",
        "model.add(Dense(8, activation='softmax'))\n",
        "\n",
        "# Summarize the model\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydh9z6n5v7YO"
      },
      "source": [
        "## 4. Model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0Hqogxkwt4w",
        "outputId": "80925305-57d1-4993-8b81-5e21dab4095b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "X_train shape : (12288, 8)\n",
            "X_test shape : (3072, 8) \n",
            "\n",
            "Epoch 1/350\n",
            "768/768 [==============================] - 8s 4ms/step - loss: 0.6454 - accuracy: 0.1221\n",
            "Epoch 2/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.5499 - accuracy: 0.1197\n",
            "Epoch 3/350\n",
            "768/768 [==============================] - 5s 6ms/step - loss: 0.4955 - accuracy: 0.1239\n",
            "Epoch 4/350\n",
            "768/768 [==============================] - 4s 6ms/step - loss: 0.4602 - accuracy: 0.1174\n",
            "Epoch 5/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.4366 - accuracy: 0.1239\n",
            "Epoch 6/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.4205 - accuracy: 0.1235\n",
            "Epoch 7/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.4091 - accuracy: 0.1239\n",
            "Epoch 8/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.4010 - accuracy: 0.1256\n",
            "Epoch 9/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.3951 - accuracy: 0.1254\n",
            "Epoch 10/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3907 - accuracy: 0.1265\n",
            "Epoch 11/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3874 - accuracy: 0.1269\n",
            "Epoch 12/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3849 - accuracy: 0.1260\n",
            "Epoch 13/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3831 - accuracy: 0.1267\n",
            "Epoch 14/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3816 - accuracy: 0.1266\n",
            "Epoch 15/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.3805 - accuracy: 0.1266\n",
            "Epoch 16/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3796 - accuracy: 0.1266\n",
            "Epoch 17/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3788 - accuracy: 0.1266\n",
            "Epoch 18/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3783 - accuracy: 0.1267\n",
            "Epoch 19/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3778 - accuracy: 0.1265\n",
            "Epoch 20/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3774 - accuracy: 0.1265\n",
            "Epoch 21/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3770 - accuracy: 0.1265\n",
            "Epoch 22/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3767 - accuracy: 0.1266\n",
            "Epoch 23/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3764 - accuracy: 0.1267\n",
            "Epoch 24/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3762 - accuracy: 0.1267\n",
            "Epoch 25/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3759 - accuracy: 0.1267\n",
            "Epoch 26/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3756 - accuracy: 0.1305\n",
            "Epoch 27/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3753 - accuracy: 0.1380\n",
            "Epoch 28/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3749 - accuracy: 0.1370\n",
            "Epoch 29/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3738 - accuracy: 0.1412\n",
            "Epoch 30/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3741 - accuracy: 0.1394\n",
            "Epoch 31/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3709 - accuracy: 0.1554\n",
            "Epoch 32/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3591 - accuracy: 0.2213\n",
            "Epoch 33/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.3464 - accuracy: 0.2708\n",
            "Epoch 34/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3380 - accuracy: 0.2988\n",
            "Epoch 35/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3422 - accuracy: 0.2790\n",
            "Epoch 36/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3283 - accuracy: 0.3386\n",
            "Epoch 37/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3300 - accuracy: 0.3247\n",
            "Epoch 38/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3322 - accuracy: 0.3320\n",
            "Epoch 39/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.3265 - accuracy: 0.3781\n",
            "Epoch 40/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3203 - accuracy: 0.3961\n",
            "Epoch 41/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3171 - accuracy: 0.4050\n",
            "Epoch 42/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3179 - accuracy: 0.3958\n",
            "Epoch 43/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.3058 - accuracy: 0.4377\n",
            "Epoch 44/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.3045 - accuracy: 0.4253\n",
            "Epoch 45/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2978 - accuracy: 0.4459\n",
            "Epoch 46/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2972 - accuracy: 0.4349\n",
            "Epoch 47/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2987 - accuracy: 0.4128\n",
            "Epoch 48/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2863 - accuracy: 0.4313\n",
            "Epoch 49/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2884 - accuracy: 0.4179\n",
            "Epoch 50/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2832 - accuracy: 0.4383\n",
            "Epoch 51/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2788 - accuracy: 0.4446\n",
            "Epoch 52/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2763 - accuracy: 0.4500\n",
            "Epoch 53/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2763 - accuracy: 0.4547\n",
            "Epoch 54/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2735 - accuracy: 0.4543\n",
            "Epoch 55/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2690 - accuracy: 0.4730\n",
            "Epoch 56/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2681 - accuracy: 0.4733\n",
            "Epoch 57/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2682 - accuracy: 0.4726\n",
            "Epoch 58/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2654 - accuracy: 0.4736\n",
            "Epoch 59/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2629 - accuracy: 0.4821\n",
            "Epoch 60/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2601 - accuracy: 0.4957\n",
            "Epoch 61/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2604 - accuracy: 0.4846\n",
            "Epoch 62/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2629 - accuracy: 0.4823\n",
            "Epoch 63/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2594 - accuracy: 0.4948\n",
            "Epoch 64/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2586 - accuracy: 0.4948\n",
            "Epoch 65/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2552 - accuracy: 0.5032\n",
            "Epoch 66/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2552 - accuracy: 0.5050\n",
            "Epoch 67/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2582 - accuracy: 0.4832\n",
            "Epoch 68/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2519 - accuracy: 0.5080\n",
            "Epoch 69/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2550 - accuracy: 0.5040\n",
            "Epoch 70/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2511 - accuracy: 0.5114\n",
            "Epoch 71/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2506 - accuracy: 0.5113\n",
            "Epoch 72/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2502 - accuracy: 0.5151\n",
            "Epoch 73/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2486 - accuracy: 0.5200\n",
            "Epoch 74/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2490 - accuracy: 0.5184\n",
            "Epoch 75/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2498 - accuracy: 0.5131\n",
            "Epoch 76/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2476 - accuracy: 0.5200\n",
            "Epoch 77/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2513 - accuracy: 0.5168\n",
            "Epoch 78/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2460 - accuracy: 0.5308\n",
            "Epoch 79/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2447 - accuracy: 0.5325\n",
            "Epoch 80/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2467 - accuracy: 0.5269\n",
            "Epoch 81/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2438 - accuracy: 0.5369\n",
            "Epoch 82/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2457 - accuracy: 0.5291\n",
            "Epoch 83/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2459 - accuracy: 0.5291\n",
            "Epoch 84/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2452 - accuracy: 0.5310\n",
            "Epoch 85/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2426 - accuracy: 0.5431\n",
            "Epoch 86/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2450 - accuracy: 0.5303\n",
            "Epoch 87/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2435 - accuracy: 0.5479\n",
            "Epoch 88/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2437 - accuracy: 0.5484\n",
            "Epoch 89/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2475 - accuracy: 0.5404\n",
            "Epoch 90/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2429 - accuracy: 0.5593\n",
            "Epoch 91/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2438 - accuracy: 0.5531\n",
            "Epoch 92/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2451 - accuracy: 0.5539\n",
            "Epoch 93/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2409 - accuracy: 0.5684\n",
            "Epoch 94/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2392 - accuracy: 0.5816\n",
            "Epoch 95/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2421 - accuracy: 0.5681\n",
            "Epoch 96/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2394 - accuracy: 0.5923\n",
            "Epoch 97/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2422 - accuracy: 0.5706\n",
            "Epoch 98/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2395 - accuracy: 0.5903\n",
            "Epoch 99/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2382 - accuracy: 0.5994\n",
            "Epoch 100/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2406 - accuracy: 0.5898\n",
            "Epoch 101/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2341 - accuracy: 0.6187\n",
            "Epoch 102/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2342 - accuracy: 0.6168\n",
            "Epoch 103/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2392 - accuracy: 0.5942\n",
            "Epoch 104/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2368 - accuracy: 0.6070\n",
            "Epoch 105/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2359 - accuracy: 0.6055\n",
            "Epoch 106/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2324 - accuracy: 0.6235\n",
            "Epoch 107/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2350 - accuracy: 0.6104\n",
            "Epoch 108/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2334 - accuracy: 0.6130\n",
            "Epoch 109/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2284 - accuracy: 0.6301\n",
            "Epoch 110/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2319 - accuracy: 0.6200\n",
            "Epoch 111/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2296 - accuracy: 0.6251\n",
            "Epoch 112/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2282 - accuracy: 0.6254\n",
            "Epoch 113/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2283 - accuracy: 0.6272\n",
            "Epoch 114/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2306 - accuracy: 0.6231\n",
            "Epoch 115/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2259 - accuracy: 0.6369\n",
            "Epoch 116/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2257 - accuracy: 0.6371\n",
            "Epoch 117/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2240 - accuracy: 0.6388\n",
            "Epoch 118/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2219 - accuracy: 0.6503\n",
            "Epoch 119/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2233 - accuracy: 0.6493\n",
            "Epoch 120/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2223 - accuracy: 0.6532\n",
            "Epoch 121/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2222 - accuracy: 0.6537\n",
            "Epoch 122/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2236 - accuracy: 0.6376\n",
            "Epoch 123/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2187 - accuracy: 0.6558\n",
            "Epoch 124/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2205 - accuracy: 0.6564\n",
            "Epoch 125/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2206 - accuracy: 0.6513\n",
            "Epoch 126/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2182 - accuracy: 0.6595\n",
            "Epoch 127/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2201 - accuracy: 0.6552\n",
            "Epoch 128/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2166 - accuracy: 0.6678\n",
            "Epoch 129/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2174 - accuracy: 0.6745\n",
            "Epoch 130/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2188 - accuracy: 0.6685\n",
            "Epoch 131/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2147 - accuracy: 0.6806\n",
            "Epoch 132/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2148 - accuracy: 0.6772\n",
            "Epoch 133/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2139 - accuracy: 0.6860\n",
            "Epoch 134/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2138 - accuracy: 0.6798\n",
            "Epoch 135/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2139 - accuracy: 0.6750\n",
            "Epoch 136/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2124 - accuracy: 0.6899\n",
            "Epoch 137/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2120 - accuracy: 0.6901\n",
            "Epoch 138/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2116 - accuracy: 0.6875\n",
            "Epoch 139/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2126 - accuracy: 0.6877\n",
            "Epoch 140/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2120 - accuracy: 0.6896\n",
            "Epoch 141/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.2117 - accuracy: 0.6972\n",
            "Epoch 142/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2109 - accuracy: 0.7026\n",
            "Epoch 143/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2094 - accuracy: 0.7103\n",
            "Epoch 144/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2077 - accuracy: 0.7114\n",
            "Epoch 145/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2069 - accuracy: 0.7165\n",
            "Epoch 146/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2042 - accuracy: 0.7294\n",
            "Epoch 147/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2025 - accuracy: 0.7362\n",
            "Epoch 148/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2025 - accuracy: 0.7349\n",
            "Epoch 149/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2015 - accuracy: 0.7403\n",
            "Epoch 150/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2006 - accuracy: 0.7401\n",
            "Epoch 151/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2018 - accuracy: 0.7416\n",
            "Epoch 152/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.2019 - accuracy: 0.7391\n",
            "Epoch 153/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2022 - accuracy: 0.7428\n",
            "Epoch 154/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2008 - accuracy: 0.7533\n",
            "Epoch 155/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2013 - accuracy: 0.7527\n",
            "Epoch 156/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1991 - accuracy: 0.7537\n",
            "Epoch 157/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.2015 - accuracy: 0.7468\n",
            "Epoch 158/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1987 - accuracy: 0.7573\n",
            "Epoch 159/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1993 - accuracy: 0.7582\n",
            "Epoch 160/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1993 - accuracy: 0.7556\n",
            "Epoch 161/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1995 - accuracy: 0.7528\n",
            "Epoch 162/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1987 - accuracy: 0.7501\n",
            "Epoch 163/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1983 - accuracy: 0.7625\n",
            "Epoch 164/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1973 - accuracy: 0.7642\n",
            "Epoch 165/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1974 - accuracy: 0.7626\n",
            "Epoch 166/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1985 - accuracy: 0.7633\n",
            "Epoch 167/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1959 - accuracy: 0.7699\n",
            "Epoch 168/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1963 - accuracy: 0.7600\n",
            "Epoch 169/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1966 - accuracy: 0.7623\n",
            "Epoch 170/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1957 - accuracy: 0.7642\n",
            "Epoch 171/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1970 - accuracy: 0.7611\n",
            "Epoch 172/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1962 - accuracy: 0.7653\n",
            "Epoch 173/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1964 - accuracy: 0.7658\n",
            "Epoch 174/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1933 - accuracy: 0.7712\n",
            "Epoch 175/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1942 - accuracy: 0.7677\n",
            "Epoch 176/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1945 - accuracy: 0.7708\n",
            "Epoch 177/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1940 - accuracy: 0.7743\n",
            "Epoch 178/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1946 - accuracy: 0.7716\n",
            "Epoch 179/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1951 - accuracy: 0.7673\n",
            "Epoch 180/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1945 - accuracy: 0.7692\n",
            "Epoch 181/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1932 - accuracy: 0.7764\n",
            "Epoch 182/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1923 - accuracy: 0.7789\n",
            "Epoch 183/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1951 - accuracy: 0.7717\n",
            "Epoch 184/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1934 - accuracy: 0.7699\n",
            "Epoch 185/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1929 - accuracy: 0.7680\n",
            "Epoch 186/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1936 - accuracy: 0.7727\n",
            "Epoch 187/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1924 - accuracy: 0.7713\n",
            "Epoch 188/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1922 - accuracy: 0.7731\n",
            "Epoch 189/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1927 - accuracy: 0.7733\n",
            "Epoch 190/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1904 - accuracy: 0.7795\n",
            "Epoch 191/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1919 - accuracy: 0.7762\n",
            "Epoch 192/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1899 - accuracy: 0.7839\n",
            "Epoch 193/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1885 - accuracy: 0.7779\n",
            "Epoch 194/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1915 - accuracy: 0.7782\n",
            "Epoch 195/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1901 - accuracy: 0.7751\n",
            "Epoch 196/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1887 - accuracy: 0.7779\n",
            "Epoch 197/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1893 - accuracy: 0.7760\n",
            "Epoch 198/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1888 - accuracy: 0.7828\n",
            "Epoch 199/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1883 - accuracy: 0.7844\n",
            "Epoch 200/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1881 - accuracy: 0.7820\n",
            "Epoch 201/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1871 - accuracy: 0.7796\n",
            "Epoch 202/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1868 - accuracy: 0.7773\n",
            "Epoch 203/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1872 - accuracy: 0.7840\n",
            "Epoch 204/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1860 - accuracy: 0.7837\n",
            "Epoch 205/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1877 - accuracy: 0.7806\n",
            "Epoch 206/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1850 - accuracy: 0.7894\n",
            "Epoch 207/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1862 - accuracy: 0.7848\n",
            "Epoch 208/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1838 - accuracy: 0.7822\n",
            "Epoch 209/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1865 - accuracy: 0.7831\n",
            "Epoch 210/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1863 - accuracy: 0.7795\n",
            "Epoch 211/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1851 - accuracy: 0.7803\n",
            "Epoch 212/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1854 - accuracy: 0.7795\n",
            "Epoch 213/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1838 - accuracy: 0.7812\n",
            "Epoch 214/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1845 - accuracy: 0.7795\n",
            "Epoch 215/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1822 - accuracy: 0.7855\n",
            "Epoch 216/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1830 - accuracy: 0.7851\n",
            "Epoch 217/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1831 - accuracy: 0.7799\n",
            "Epoch 218/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1833 - accuracy: 0.7794\n",
            "Epoch 219/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1843 - accuracy: 0.7786\n",
            "Epoch 220/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1835 - accuracy: 0.7801\n",
            "Epoch 221/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1812 - accuracy: 0.7883\n",
            "Epoch 222/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1838 - accuracy: 0.7769\n",
            "Epoch 223/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1808 - accuracy: 0.7891\n",
            "Epoch 224/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1825 - accuracy: 0.7755\n",
            "Epoch 225/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1818 - accuracy: 0.7845\n",
            "Epoch 226/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1806 - accuracy: 0.7801\n",
            "Epoch 227/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1818 - accuracy: 0.7824\n",
            "Epoch 228/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1791 - accuracy: 0.7793\n",
            "Epoch 229/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1809 - accuracy: 0.7825\n",
            "Epoch 230/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1806 - accuracy: 0.7773\n",
            "Epoch 231/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1823 - accuracy: 0.7747\n",
            "Epoch 232/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1794 - accuracy: 0.7826\n",
            "Epoch 233/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1793 - accuracy: 0.7834\n",
            "Epoch 234/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1792 - accuracy: 0.7799\n",
            "Epoch 235/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1789 - accuracy: 0.7801\n",
            "Epoch 236/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1794 - accuracy: 0.7731\n",
            "Epoch 237/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1799 - accuracy: 0.7760\n",
            "Epoch 238/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1779 - accuracy: 0.7802\n",
            "Epoch 239/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1781 - accuracy: 0.7807\n",
            "Epoch 240/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1789 - accuracy: 0.7716\n",
            "Epoch 241/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1787 - accuracy: 0.7770\n",
            "Epoch 242/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1788 - accuracy: 0.7763\n",
            "Epoch 243/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1767 - accuracy: 0.7830\n",
            "Epoch 244/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1798 - accuracy: 0.7787\n",
            "Epoch 245/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1780 - accuracy: 0.7745\n",
            "Epoch 246/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1782 - accuracy: 0.7794\n",
            "Epoch 247/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1772 - accuracy: 0.7798\n",
            "Epoch 248/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1766 - accuracy: 0.7839\n",
            "Epoch 249/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1778 - accuracy: 0.7779\n",
            "Epoch 250/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1767 - accuracy: 0.7819\n",
            "Epoch 251/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1781 - accuracy: 0.7782\n",
            "Epoch 252/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1776 - accuracy: 0.7774\n",
            "Epoch 253/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1776 - accuracy: 0.7779\n",
            "Epoch 254/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1770 - accuracy: 0.7748\n",
            "Epoch 255/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1762 - accuracy: 0.7765\n",
            "Epoch 256/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1761 - accuracy: 0.7800\n",
            "Epoch 257/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1770 - accuracy: 0.7805\n",
            "Epoch 258/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1762 - accuracy: 0.7762\n",
            "Epoch 259/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1780 - accuracy: 0.7830\n",
            "Epoch 260/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1757 - accuracy: 0.7834\n",
            "Epoch 261/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1754 - accuracy: 0.7862\n",
            "Epoch 262/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1787 - accuracy: 0.7699\n",
            "Epoch 263/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1768 - accuracy: 0.7747\n",
            "Epoch 264/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1761 - accuracy: 0.7825\n",
            "Epoch 265/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1763 - accuracy: 0.7760\n",
            "Epoch 266/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1760 - accuracy: 0.7807\n",
            "Epoch 267/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1759 - accuracy: 0.7787\n",
            "Epoch 268/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1760 - accuracy: 0.7782\n",
            "Epoch 269/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1751 - accuracy: 0.7729\n",
            "Epoch 270/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1771 - accuracy: 0.7758\n",
            "Epoch 271/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.7758\n",
            "Epoch 272/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1746 - accuracy: 0.7811\n",
            "Epoch 273/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1746 - accuracy: 0.7830\n",
            "Epoch 274/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1750 - accuracy: 0.7770\n",
            "Epoch 275/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1757 - accuracy: 0.7802\n",
            "Epoch 276/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1752 - accuracy: 0.7788\n",
            "Epoch 277/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1733 - accuracy: 0.7798\n",
            "Epoch 278/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1748 - accuracy: 0.7752\n",
            "Epoch 279/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1748 - accuracy: 0.7784\n",
            "Epoch 280/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1735 - accuracy: 0.7839\n",
            "Epoch 281/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1757 - accuracy: 0.7717\n",
            "Epoch 282/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1747 - accuracy: 0.7769\n",
            "Epoch 283/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1750 - accuracy: 0.7755\n",
            "Epoch 284/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1749 - accuracy: 0.7835\n",
            "Epoch 285/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1735 - accuracy: 0.7830\n",
            "Epoch 286/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1734 - accuracy: 0.7873\n",
            "Epoch 287/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1755 - accuracy: 0.7795\n",
            "Epoch 288/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1734 - accuracy: 0.7778\n",
            "Epoch 289/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1735 - accuracy: 0.7809\n",
            "Epoch 290/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1745 - accuracy: 0.7755\n",
            "Epoch 291/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1741 - accuracy: 0.7756\n",
            "Epoch 292/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1737 - accuracy: 0.7831\n",
            "Epoch 293/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1732 - accuracy: 0.7809\n",
            "Epoch 294/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1742 - accuracy: 0.7764\n",
            "Epoch 295/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1750 - accuracy: 0.7806\n",
            "Epoch 296/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1728 - accuracy: 0.7766\n",
            "Epoch 297/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1732 - accuracy: 0.7783\n",
            "Epoch 298/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1727 - accuracy: 0.7792\n",
            "Epoch 299/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1724 - accuracy: 0.7821\n",
            "Epoch 300/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1746 - accuracy: 0.7726\n",
            "Epoch 301/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1733 - accuracy: 0.7811\n",
            "Epoch 302/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1731 - accuracy: 0.7773\n",
            "Epoch 303/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1726 - accuracy: 0.7797\n",
            "Epoch 304/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1754 - accuracy: 0.7765\n",
            "Epoch 305/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1736 - accuracy: 0.7843\n",
            "Epoch 306/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1722 - accuracy: 0.7830\n",
            "Epoch 307/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1726 - accuracy: 0.7804\n",
            "Epoch 308/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1735 - accuracy: 0.7796\n",
            "Epoch 309/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1723 - accuracy: 0.7846\n",
            "Epoch 310/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1732 - accuracy: 0.7855\n",
            "Epoch 311/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1723 - accuracy: 0.7830\n",
            "Epoch 312/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1729 - accuracy: 0.7806\n",
            "Epoch 313/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1718 - accuracy: 0.7867\n",
            "Epoch 314/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1729 - accuracy: 0.7739\n",
            "Epoch 315/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1727 - accuracy: 0.7761\n",
            "Epoch 316/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1734 - accuracy: 0.7771\n",
            "Epoch 317/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1736 - accuracy: 0.7790\n",
            "Epoch 318/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1727 - accuracy: 0.7784\n",
            "Epoch 319/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1727 - accuracy: 0.7817\n",
            "Epoch 320/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1752 - accuracy: 0.7736\n",
            "Epoch 321/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1719 - accuracy: 0.7819\n",
            "Epoch 322/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1722 - accuracy: 0.7778\n",
            "Epoch 323/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1731 - accuracy: 0.7723\n",
            "Epoch 324/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1716 - accuracy: 0.7830\n",
            "Epoch 325/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1719 - accuracy: 0.7847\n",
            "Epoch 326/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1711 - accuracy: 0.7818\n",
            "Epoch 327/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1722 - accuracy: 0.7826\n",
            "Epoch 328/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1722 - accuracy: 0.7788\n",
            "Epoch 329/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1713 - accuracy: 0.7850\n",
            "Epoch 330/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1728 - accuracy: 0.7837\n",
            "Epoch 331/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1720 - accuracy: 0.7756\n",
            "Epoch 332/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1732 - accuracy: 0.7726\n",
            "Epoch 333/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1715 - accuracy: 0.7794\n",
            "Epoch 334/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1708 - accuracy: 0.7826\n",
            "Epoch 335/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1710 - accuracy: 0.7733\n",
            "Epoch 336/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1717 - accuracy: 0.7843\n",
            "Epoch 337/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1716 - accuracy: 0.7845\n",
            "Epoch 338/350\n",
            "768/768 [==============================] - 3s 3ms/step - loss: 0.1708 - accuracy: 0.7846\n",
            "Epoch 339/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1723 - accuracy: 0.7804\n",
            "Epoch 340/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1712 - accuracy: 0.7792\n",
            "Epoch 341/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1714 - accuracy: 0.7752\n",
            "Epoch 342/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1702 - accuracy: 0.7839\n",
            "Epoch 343/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1705 - accuracy: 0.7826\n",
            "Epoch 344/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1694 - accuracy: 0.7847\n",
            "Epoch 345/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1722 - accuracy: 0.7835\n",
            "Epoch 346/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1715 - accuracy: 0.7806\n",
            "Epoch 347/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1712 - accuracy: 0.7811\n",
            "Epoch 348/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1724 - accuracy: 0.7777\n",
            "Epoch 349/350\n",
            "768/768 [==============================] - 3s 4ms/step - loss: 0.1701 - accuracy: 0.7789\n",
            "Epoch 350/350\n",
            "768/768 [==============================] - 2s 3ms/step - loss: 0.1718 - accuracy: 0.7847\n"
          ]
        }
      ],
      "source": [
        "# Split training data into train and validation\n",
        "# (here 20% of the data will be used for the training and 80% for the testing)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_train_encoded, y_train_encoded, test_size=0.2)\n",
        "print('\\nX_train shape :', X_train.shape)\n",
        "print('X_test shape :', X_test.shape, '\\n')\n",
        "\n",
        "# Compile the model & Set the loss function\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "# Model training\n",
        "history = model.fit(X_train, Y_train, epochs=300, batch_size=16, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc5_EQb1v62a"
      },
      "source": [
        "##5. Performance tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfChcKXdYSJn"
      },
      "source": [
        "*   Number of hidden layers (with 16 neurons for each layer, activation='softmax', test_size=0.2, learning_rate=0.01, epochs=200, batch_size=16) :\n",
        "  - 1: Loss = 33.08% ; Acc = 25.21%\n",
        "  - **2: Loss = 37.27% ; Acc = 26.58%**\n",
        "  - 3: Loss = 37.68% ; Acc = 12.75%\n",
        "  - 5: Loss = 37.68% ; Acc = 12.87%\n",
        "  - 8: Loss = 37.68% ; Acc = 12.66%\n",
        "\n",
        "**Best score with 2 hidden layers (16 & 16 neurons)**\n",
        "\n",
        "\n",
        "*   Number of neurons (2 hidden layers, activation='softmax', test_size=0.2, learning_rate=0.01, epochs=200, batch_size=16) : \n",
        "  - 4, 4: Loss = 32.06 % ; Acc = 25.74%\n",
        "  -\t4, 8: Loss = 32.11 % ; Acc = 26.16%\n",
        "  -\t4, 16:\t Loss = 32.17% ; Acc = 27.61%\n",
        "  -\t**8, 4: Loss = 26.61% ; Acc = 37.28%**\n",
        "  -\t8, 8: Loss = 33.24% ; Acc = 25.09%\n",
        "  -\t8, 16: Loss = 32.20% ; Acc = 26.48%\n",
        "  -\t16, 4: Loss = 26.64% ; Acc = 37.63%\n",
        "  -\t16, 8: Loss = 26.60%% ; Acc = 37.00%\n",
        "  -\t16, 16: Loss = 32.54% ; Acc = 24.92%\n",
        "\n",
        "**Best score is 8 neurons for the first hidden layer and 4 for the second hidden layer, because easier to compute than 16,4 and 16,8**\n",
        "\n",
        "\n",
        "*   learning_rate (2 hidden layers, 8 and 4 neurons, activation='softmax', test_size=0.2, epochs=100, batch_size=16, values are decreased because of 100 epochs instead of 200 for optimize time of testing) : \n",
        "  - 0.001: Loss = 38.12% ; Acc = 13.80%\n",
        "  - **0.01: Loss = 32.66% ; Acc = 27.40%**\n",
        "  - 0.1: Loss = 31.55% ; Acc = 24.66%\n",
        "  - 0.5: Loss = 31.46% ; Acc = 24.76%\n",
        "  -\t1.0: Loss = 31.48% ; Acc = 24.34%\n",
        "\n",
        "**Best score with learning_rate = 0,01**\n",
        "\n",
        "\n",
        "*   epochs (2 hidden layers, 8 and 4 neurons, activation='softmax', test_size=0.2, learning_rate=0.01, batch_size=16) :\n",
        "  - 10: Loss = 38.20% ; Acc = 13.07%\n",
        "  - 20: Loss = 36.60% ; Acc = 24.99%\n",
        "  - 50: Loss = 36.95% ; Acc = 32.71%\n",
        "  - 100: Loss = 32.66% ; Acc = 27.40%\n",
        "  - **200: Loss = 26.61% ; Acc = 37.28%**\n",
        "  - 1000: Loss = 31.55% ; Acc = 25.18%\n",
        "  - 2000: Loss = 31.49% ; Acc = 25.11%\n",
        "\n",
        "**Best score with epochs=200 . It seems that when increasing number of epochs, Loss tends to 0% and Accuracy tends to 37,5%.**\n",
        "\n",
        "\n",
        "*   batch_size (2 hidden layers, 8 and 4 neurons, activation='softmax', test_size=0.2, learning_rate=0.01, epochs=100, values are decreased because of 100 epochs instead of 200 for optimize time of testing) :\n",
        "  - 8: Loss = 31.89% ; Acc = 25.38%\n",
        "  - **16: Loss = 32.66% ; Acc = 27.40%**\n",
        "  - 32: Loss = 36.01% ; Acc = 25.05%\n",
        "  - 64: Loss = 37.39% ; Acc = 24.79%\n",
        "  - 128: Loss = 37.62% ; Acc = 12.82%\n",
        "\n",
        "**Best score with batch_size = 16**\n",
        "\n",
        "\n",
        "*   test_size (2 hidden layers, 8 and 4 neurons,activation='softmax', learning_rate=0.01, epochs=100, batch_size=16, values are decreased because of 100 epochs instead of 200 for optimize time of testing) :\n",
        "  -\t0.1: Loss = 32.60% ; Acc = 25.05%\n",
        "  -\t0.15: Loss = 33.09% ; Acc = 24.70%\n",
        "  -\t**0.2: Loss = 32.66% ; Acc = 27.40%**\n",
        "  -\t0.5: Loss = 34.49% ; Acc = 24.57%\n",
        "  -\t1.0: Loss = 32.41% ; Acc = 25.37%\n",
        "\n",
        "**Best score with test_size = 0,2**\n",
        "\n",
        "*   activation function (2 hidden layers, 8 and 4 neurons, test_size=0.2, learning_rate=0.01, epochs=200, batch_size=16) :\n",
        "  - elu: Loss = 37.68% ; Acc = 12.75%\n",
        "  - selu: Loss = 30.27% ; Acc = 32.36%\n",
        "  - sigmoïd: Loss = 31.80% ; Acc = 24.88%\n",
        "  - softmax: Loss = 32.66% ; Acc = 27.40%\n",
        "  - softplus: Loss = 23.45% ; Acc = 65.65%\n",
        "  - softsign: Loss = 23.92% ; Acc = 49.36%\n",
        "  -\t**relu: Loss = 06.91% ; Acc = 93.37%**\n",
        "\n",
        "**Best score with the relu activation function**\n",
        "\n",
        "Finally, best score is obtained with these parameters:\n",
        "*   2 hidden layers:\n",
        "  - First one with 8 neurons;\n",
        "  - Second one with 4 neurons;\n",
        "*   test_size = 0.2;\n",
        "*   learning_rate = 0.01;\n",
        "*   epochs = 200;\n",
        "*   batch_size = 16;\n",
        "*   activation = relu;\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-CdAvajwA0J"
      },
      "source": [
        "##6. Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BeUMxymtwwkG",
        "outputId": "615ec801-347c-4c67-a72a-d0e349b03245"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Loss: 16.41%\n",
            "Accuracy: 81.00%\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(X_train, Y_train, verbose=0)\n",
        "\n",
        "# Print final accuracy and loss\n",
        "print('\\nLoss: {:.2f}%'.format(loss*100))\n",
        "print('Accuracy: {:.2f}%\\n'.format(accuracy*100))\n",
        "\n",
        "# Plot the Loss graphic\n",
        "plt.figure()\n",
        "plt.plot(history.history['loss'])\n",
        "plt.xlabel('N° of epochs')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "# Plot the Accuracy graphic\n",
        "plt.figure()\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.xlabel('N° of epochs')\n",
        "plt.ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07ctVdi6wXUP"
      },
      "source": [
        "##7. Compare MLP to SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "XGMkr4b-wySP",
        "outputId": "20b32331-08e8-4320-e802-eff7a7c50d85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SVM parameters : {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'linear', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
            "\n",
            "SVM score : 0.9996744791666666\n"
          ]
        }
      ],
      "source": [
        "# Split training data into train and validation\n",
        "# (here 20% of the data will be used for the training and 80% for the testing)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(x_train_encoded, y_train_column2, test_size=0.2)\n",
        "\n",
        "# Create a SVM model\n",
        "SVMmodel=SVC(kernel='linear') # Linear kernel will search for separate lines --> Definition of the kernel parameters\n",
        "\n",
        "# Feed the SVM\n",
        "SVMmodel.fit(X_train, Y_train)\n",
        "\n",
        "# Check what are the parameters\n",
        "SVMmodel.get_params()\n",
        "print('SVM parameters :', SVMmodel.get_params())\n",
        "\n",
        "# Check how good it classifies\n",
        "SVMmodel.score(X_test, Y_test)\n",
        "print('\\nSVM score :', SVMmodel.score(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e0b7u1iwlSP"
      },
      "source": [
        "##8. Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sVg7ymfbwzmZ"
      },
      "outputs": [],
      "source": [
        "# CODE 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jxR714ArvKnI"
      },
      "source": [
        "##9. Kaggle CSV file generation\n",
        "\n",
        "The final part of the project is to create a CSV file from Y_test values and import it on Kaggle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "F_AskVuNvJ0m",
        "outputId": "7cc32949-4580-40a6-aa3d-82cad093205d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "120/120 [==============================] - 0s 1ms/step\n",
            "\n",
            "y_pred :\n",
            "(3840, 8)\n",
            "[[2.6827227e-02 4.6453916e-02 3.3298947e-04 ... 2.6114924e-02\n",
            "  3.2289424e-03 3.0353261e-04]\n",
            " [1.6984102e-01 6.0159966e-02 1.7707500e-01 ... 9.8350890e-02\n",
            "  5.0166191e-06 4.9343318e-01]\n",
            " [2.6827227e-02 4.6453916e-02 3.3298947e-04 ... 2.6114924e-02\n",
            "  3.2289424e-03 3.0353261e-04]\n",
            " ...\n",
            " [3.0923063e-01 3.9156047e-01 9.1974363e-03 ... 2.7170894e-01\n",
            "  7.2231889e-03 1.0451019e-02]\n",
            " [2.9196262e-05 2.6830015e-05 8.3174717e-01 ... 1.5370589e-01\n",
            "  1.7687918e-05 2.6857385e-03]\n",
            " [3.5290417e-01 2.6682684e-01 4.4290744e-02 ... 2.6192611e-01\n",
            "  5.5338437e-04 7.2359852e-02]]\n",
            "\n",
            "y_test :\n",
            "(3840, 1)\n",
            "[[5]\n",
            " [8]\n",
            " [5]\n",
            " ...\n",
            " [2]\n",
            " [3]\n",
            " [1]]\n"
          ]
        }
      ],
      "source": [
        "# Predict the model\n",
        "y_pred = model.predict(x_test)\n",
        "\n",
        "# Display y_pred\n",
        "print('\\ny_pred :')\n",
        "print(y_pred.shape)\n",
        "print(y_pred)\n",
        "\n",
        "# Get column index of highest value for each line\n",
        "y_test = np.argmax(y_pred, axis=1)\n",
        "y_test = y_test.reshape(3840, 1)\n",
        "\n",
        "# Add 1 à chaque ligne (Python index begins at 0 and not 1)\n",
        "for i in range(len(y_test)):\n",
        "  y_test[i] += 1\n",
        "\n",
        "# Display y_test\n",
        "print('\\ny_test :')\n",
        "print(y_test.shape)\n",
        "print(y_test)\n",
        "\n",
        "# Create the dataframe\n",
        "y_test_dataframe = pd.DataFrame(y_test, columns=['target'])\n",
        "\n",
        "# Save the dataframe into a CSV file \n",
        "y_test_dataframe.to_csv('y_test.csv', index_label='id') "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}